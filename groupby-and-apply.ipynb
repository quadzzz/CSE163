{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bd8481-10ce-4664-a4b4-6ef333327a81",
   "metadata": {},
   "source": [
    "# Groupby and Apply\n",
    "\n",
    "In this lesson, we'll discuss two common `DataFrame` programming patterns called **group by** and **apply**. By the end of this lesson, students will be able to:\n",
    "\n",
    "- Explain in plain English the outcome of a `pandas` `DataFrame` **group by** operation.\n",
    "- Apply the **group by** operation to a list of dictionaries and to a `pandas` `DataFrame`.\n",
    "- Apply the **apply** operation to a list of dictionaries and to a `pandas` `DataFrame`.\n",
    "\n",
    "Previously, we learned how to find the largest earthquake in a dataset using both a list of dictionaries and using a `pandas` `DataFrame`. How about finding the largest earthquake for each place in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18294de3-1e19-4a75-b9f1-d94ec407e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf33f37-c630-448b-9337-b4951e166db1",
   "metadata": {},
   "source": [
    "To help visualize our work, the following dataset contains the first 12 rows from `earthquakes.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83258f-8bd6-4204-a760-d6b1aa8c35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"\"\"\n",
    "id,year,month,day,latitude,longitude,name,magnitude\n",
    "nc72666881,2016,7,27,37.6723333,-121.619,California,1.43\n",
    "us20006i0y,2016,7,27,21.5146,94.5721,Burma,4.9\n",
    "nc72666891,2016,7,27,37.5765,-118.85916670000002,California,0.06\n",
    "nc72666896,2016,7,27,37.5958333,-118.99483329999998,California,0.4\n",
    "nn00553447,2016,7,27,39.3775,-119.845,Nevada,0.3\n",
    "ak13805337,2016,7,27,61.2963,-152.46,Alaska,1.8\n",
    "hv61354276,2016,7,27,19.4235,-155.60983330000005,Hawaii,1.0\n",
    "ak13805339,2016,7,27,61.3019,-152.4507,Alaska,2.0\n",
    "ci37640584,2016,7,27,35.503,-118.40583329999998,California,1.2\n",
    "nc72666901,2016,7,27,37.673,-121.6133333,California,1.67\n",
    "ci37640592,2016,7,27,33.5888333,-116.8165,California,0.48\n",
    "nn00553416,2016,7,27,38.2638,-118.7351,Nevada,0.9\n",
    "\"\"\"\n",
    "\n",
    "earthquakes = pd.read_csv(io.StringIO(csv), index_col=\"id\")\n",
    "earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743ed84-7dc0-4887-b952-f923ad2251aa",
   "metadata": {},
   "source": [
    "## Groupby in plain Python\n",
    "\n",
    "Let's first see how we can solve this problem using the list of dictionaries approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18f549-f70f-4348-b277-6fe285a9bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for earthquake in earthquakes.to_dict(\"records\"): # Convert to list of dictionaries\n",
    "    if earthquake[\"name\"] not in result or earthquake[\"magnitude\"] > result[earthquake[\"name\"]]:\n",
    "        result[earthquake[\"name\"]] = earthquake[\"magnitude\"]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c1edf5-8677-4384-97a2-11486ff568cf",
   "metadata": {},
   "source": [
    "## Groupby in Pandas\n",
    "\n",
    "The inventors of `pandas` defined a `DataFrame` function called `groupby` to streamline this operation into a single expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01c3ce-4e3b-4c8b-be23-5e5bfb8f958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes.groupby(\"name\")[\"magnitude\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d350af-34b6-40b2-b33b-b1febd78e4c8",
   "metadata": {},
   "source": [
    "What's going on here? We can take a closer view at each step of the process in [PandasTutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20%22%22%22%0Aid,year,month,day,latitude,longitude,name,magnitude%0Anc72666881,2016,7,27,37.6723333,-121.619,California,1.43%0Aus20006i0y,2016,7,27,21.5146,94.5721,Burma,4.9%0Anc72666891,2016,7,27,37.5765,-118.85916670000002,California,0.06%0Anc72666896,2016,7,27,37.5958333,-118.99483329999998,California,0.4%0Ann00553447,2016,7,27,39.3775,-119.845,Nevada,0.3%0Aak13805337,2016,7,27,61.2963,-152.46,Alaska,1.8%0Ahv61354276,2016,7,27,19.4235,-155.60983330000005,Hawaii,1.0%0Aak13805339,2016,7,27,61.3019,-152.4507,Alaska,2.0%0Aci37640584,2016,7,27,35.503,-118.40583329999998,California,1.2%0Anc72666901,2016,7,27,37.673,-121.6133333,California,1.67%0Aci37640592,2016,7,27,33.5888333,-116.8165,California,0.48%0Ann00553416,2016,7,27,38.2638,-118.7351,Nevada,0.9%0A%22%22%22%0A%0Aearthquakes%20%3D%20pd.read_csv%28io.StringIO%28csv%29,%20index_col%3D%22id%22%29%0Aearthquakes.groupby%28%22name%22%29%5B%22magnitude%22%5D.max%28%29&d=2024-01-16&lang=py&v=v1). In summary, this expression:\n",
    "\n",
    "1. Calls `earthquakes.groupby(\"name\")` to split the `earthquakes` into groups by `\"name\"`.\n",
    "1. For each group, selects the column `\"magnitude\"` indicated in square brackets.\n",
    "1. Combines (summarizes) each group on the selected column using the `max()` function.\n",
    "\n",
    "`groupby` help us quickly answer questions involving \"grouping by\" one or more columns and then summarizing data in another column.\n",
    "\n",
    "The best part about `pandas` `groupby` is that it allows us to quickly answer many different kinds of questions following the same format. For example, suppose we want to compute descriptive statistics for all the earthquake magnitudes that occurred on each day. Let's read the full dataset and try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aba538-2e13-4492-8685-f978695bded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes = pd.read_csv(\"earthquakes.csv\", index_col=\"id\")\n",
    "earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe4b52-5475-457c-8ef0-e180120cd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day = earthquakes.groupby([\"year\", \"month\", \"day\"])[\"magnitude\"].describe()\n",
    "magnitudes_per_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f0eb9-42e6-4a34-9da6-64ce62fa92e6",
   "metadata": {},
   "source": [
    "Explain in your own words the result of the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb9cc3-3044-4899-89d4-ce7033d3fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes.groupby(\"name\")[\"latitude\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50421cc-ddc7-4c00-ac4a-59c705cc73ec",
   "metadata": {},
   "source": [
    "## Hierarchical indexing\n",
    "\n",
    "If you look closely at the `magnitudes_per_day` `DataFrame`, you'll notice something interesting: there are three index columns in bold on the left to denote each `year`, `month`, and `day` group. In `pandas`, a `DataFrame` can have a hierarchical (aka multi-level) index called a `MultiIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe970d4-49d9-4bf8-8e36-2567fd64622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e4343-ab9b-48c8-b581-9fef12d1e134",
   "metadata": {},
   "source": [
    "A `MultiIndex` is `.loc`-accessible with Python tuples. However, the syntax is somewhat unusual, particularly when combined with slicing due to limitations in the Python programming language. For each example below, predict the output type (single value, 1-d `Series`, or 2-d `DataFrame`) as well as the contents of the output before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0ad53-33b5-4712-a4dd-aab902011f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.loc[(2016, 7, 27), \"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13093c8-e50f-4a87-a375-981a19af2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.loc[:, \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef03a7-709f-4432-8772-8196078a4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.loc[(2016, 8, 10:15), \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0abba4-7184-4758-9f5c-ef2c4ace0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.loc[[(2016, 8, 1), (2016, 8, 15)], \"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8894b5d-269b-4238-a9e8-6aaeb5348094",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.loc[magnitudes_per_day[\"count\"] < 220, \"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15fca1-6a14-434e-abec-6b1fe320604c",
   "metadata": {},
   "source": [
    "We can define boolean series using levels from a `MultiIndex` by calling `get_level_values(level)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c8e57-ac59-4db8-88a6-5a70c878c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_per_day.index.get_level_values(\"month\") == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd028cbd-465e-4134-8647-4bed366f37ef",
   "metadata": {},
   "source": [
    "## Practice: UFO sightings\n",
    "\n",
    "UFO (unidentified flying object) sightings have received attention from US Congress in the past couple years. We've collected a public dataset consisting of 1001 reported UFO sightings around the world to help us practice `groupby` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1dc5c-a4de-4701-a1b9-3735b8f2f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos = pd.read_csv(\"ufos.csv\", index_col=\"datetime\")\n",
    "ufos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72357519-46aa-4ce4-a9b2-9eaa5821be5e",
   "metadata": {},
   "source": [
    "Compute the average (mean) `\"duration (seconds)\"` for each UFO `\"shape\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2409c-960b-46a3-9c19-704a3ab67098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba48e567-47a8-4310-8ccc-f5c11ee82930",
   "metadata": {},
   "source": [
    "Since we're focusing on US Congress, identify the UFO sighting with the longest `\"duration (seconds)\"` for each `\"city\"` in the US (`\"us\"`). Do not include any cities outside the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579a8f2-6c45-4f5b-8c83-407059c16563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6dda373-a40e-44ea-9350-886630b6eddd",
   "metadata": {},
   "source": [
    "What is the name of the `\"city\"` that has the largest count of UFO sightings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0fbfc-5a4f-4d85-9433-88ff8fbd4962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed6378c6-8677-44ec-8dff-f3411ec3c4df",
   "metadata": {},
   "source": [
    "## String accessor functions\n",
    "\n",
    "In data science, many tasks involve string data. In plain Python, we know that we can call string functions like `split()` to split a string on whitespace or `find(target)` to find the index that a target appears in a string.\n",
    "\n",
    "To help improve readability of code, the inventors of `pandas` provide these functions as element-wise operations but hide them behind a special `.str` string accessor such as `s.str.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fd015-99b3-487b-8866-e23dd4a99f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos[\"comments\"].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26e602-1634-47b7-80b2-a5fd37695ba7",
   "metadata": {},
   "source": [
    "The above expression splits each comment by whitespace. This isn't too useful on its own, but we can then compute the length of each list to find the number of words in each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865c73b-53a3-42fc-8ec3-58337c139762",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos[\"comments\"].str.split().str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159e9d-13f2-4290-9f02-88ab5a0dcaa0",
   "metadata": {},
   "source": [
    "These functions don't modify the original `DataFrame`. To add the result as a new column in the original `DataFrame`, use an assignment statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316240f-6e92-487b-a820-f4b529fdf77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos[\"word count\"] = ufos[\"comments\"].str.split().str.len()\n",
    "ufos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6de27-e39a-4025-9217-a08fa5ab92f5",
   "metadata": {},
   "source": [
    "## Apply your own functions\n",
    "\n",
    "So what if you want to call your own functions on each element? Call the `apply(...)` function on a `Series` or `DataFrame` and pass in another function as an argument. Let's try writing a program that can remove the trailing parentheticals in the city name for the UFO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e37ee-ce61-4c06-beab-4eb56443a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_city_name(s):\n",
    "    \"\"\"\n",
    "    Returns all the characters in the given string with trailing parentheticals removed.\n",
    "\n",
    "    >>> clean_city_name(\"seattle (ballard area)\")\n",
    "    'seattle'\n",
    "    >>> clean_city_name(\"seattle (west)\")\n",
    "    'seattle'\n",
    "    >>> clean_city_name(\"melbourne (vic&#44 australia)\")\n",
    "    'melbourne'\n",
    "    >>> clean_city_name(\"chester (uk/england)\")\n",
    "    'chester'\n",
    "    >>> clean_city_name(\"carrieres sous poissy (france)\")\n",
    "    'carrieres sous poissy'\n",
    "    >>> clean_city_name(\"seattle\")\n",
    "    'seattle'\n",
    "    \"\"\"\n",
    "    index = s.find(\"(\")\n",
    "    if index == -1:\n",
    "        return s\n",
    "    return s[:index].rstrip()\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba648b6-bd65-443b-a514-b22f8057f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_city_counts = ufos[\"city\"].apply(clean_city_name).to_frame().groupby(\"city\")[\"city\"].count()\n",
    "# Call to_frame() due to limitations of Series.groupby; DataFrame.groupby works better\n",
    "ufo_city_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8dff27-7505-40ff-b7a5-a24179142371",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_city_counts[ufo_city_counts == ufo_city_counts.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921b153-f864-4f25-a7ae-8c70b2a5424d",
   "metadata": {},
   "source": [
    "In practice, this can be useful for carrying-out data cleaning tasks such as removing punctuation or converting special characters. `apply` lets us write and test a function that achieves our task on a single string, and then apply that function to every string in a dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
