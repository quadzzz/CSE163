{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c097be-42db-4453-a30a-e239d8bbd913",
   "metadata": {},
   "source": [
    "# Data Frames\n",
    "\n",
    "Last week, we learned how to process CSV files using the list of dictionaries representation. This week, we will introduce `pandas`, the most commonly-used Python data programming tool and one that we'll be using for the remainder of the course. By the end of this lesson, students will be able to:\n",
    "\n",
    "- Import values and functions from another module using `import` and `from` statements.\n",
    "- Select individual columns from a `pandas` `DataFrame` and apply element-wise computations.\n",
    "- Filter a `pandas` `DataFrame` or `Series` with a mask.\n",
    "\n",
    "The last two learning objectives are particularly ambitious: it will take much more drill and deliberate practice before you will feel fully comfortable.\n",
    "\n",
    "## Import statements\n",
    "\n",
    "We've been writing a couple curious lines of code called **import statements** that deserve a short explanation: importing the `doctest` module for running our doctests and importing the `pandas` module for reading CSV data. The word **module** refers to code written in a standalone file designed to be used in another program.\n",
    "\n",
    "The simplest syntax uses the `import` statement to import a module like `doctest`. We can then call the definitions within that module like `doctest.testmod()` to run all our doctests.\n",
    "\n",
    "```python\n",
    "import doctest\n",
    "doctest.testmod()\n",
    "```\n",
    "\n",
    "We can also import a module and rename it to a more convenient shorthand, like `pd` instead of `pandas`. We can then call the definitions within the module like `pd.read_csv(path).to_dict(\"records\")` to read a CSV file and then convert it into our list of dictionaries (\"records\") representation.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "earthquakes = pd.read_csv(path).to_dict(\"records\")\n",
    "```\n",
    "\n",
    "Finally, Python can also import just a single definition from a module. Here, we ask Python to only import `Counter` from the `collections` module.\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "with open(path) as f:\n",
    "    return Counter(f.read().split())\n",
    "```\n",
    "\n",
    "A common practice in notebooks is to add your imports to the first code cell at the top of your notebook so that someone who's running your notebook will know what modules they will need to be able to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dccbeb-f892-432d-ab04-6a775982aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316cfb60-c6c7-419e-b224-e492d45f5899",
   "metadata": {},
   "source": [
    "To create a dataframe, call `pd.read_csv(path)`. In addition to reading CSV data from a file, `pd.read_csv` also accepts `io.StringIO` to read-in CSV data directly from a Python string for specifying small datasets directly in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2bc0a-87d3-44c6-8b10-ae3043ed380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"\"\"\n",
    "Name,Hours\n",
    "Anna,20\n",
    "Iris,15\n",
    "Abiy,10\n",
    "Gege,12\n",
    "\"\"\"\n",
    "\n",
    "staff = pd.read_csv(io.StringIO(csv))\n",
    "staff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c5f18-9310-4505-8a5e-1919ac963448",
   "metadata": {},
   "source": [
    "The **index** of a `DataFrame` appears in bold across the left (rows) and defines the keys for accessing values in a data frame. Like keys in a dictionary, the keys in an index should be unique.\n",
    "\n",
    "By default, an integer index is provided, but you'll often want to set a more meaningful index. We can use the `df.set_index(colname)` function to return a new `DataFrame` with a more meaningful index that will be handy for later. In the example below, we assume that each TA has a unique name, though this assumption has severe limits in practice: people can change their names, or we might eventually run a course where two people share the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c43281-03db-4595-b6e7-68d50c678a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff = staff.set_index(\"Name\")\n",
    "staff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e21aa3-787c-40d6-8e49-73e384b1fcad",
   "metadata": {},
   "source": [
    "## Column indexers\n",
    "\n",
    "In `pandas`, tabular data is represented by a `DataFrame` as shown above. Unlike the list of dictionaries format that required us to write a loop to access the name of every TA, `pandas` provides special syntax to help us achieve this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5bc85-2e3b-4672-9d43-8a13d2434e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960097c5-06c6-45c5-b081-45a69af1c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff[\"Hours\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac844219-7ffb-4439-a823-e25892a3cc0b",
   "metadata": {},
   "source": [
    "`df[\"Hours\"]` returns a `pandas` object called a `Series` that represents a single column or row of a `DataFrame`. A `Series` is very similar to a `list` from Python, but has several convenient functions for data analysis.\n",
    "\n",
    "- `s.mean()` returns the average value in `s`.\n",
    "- `s.min()` returns the minimum value in `s`.\n",
    "  - `s.idxmin()` returns the label of the minimum value in `s`.\n",
    "- `s.max()` returns the maximum value in `s`.\n",
    "  - `s.idxmax()` returns the label of the maximum value in `s`.\n",
    "- `s.unique()` returns a new `Series` with all the unique values in `s`.\n",
    "- `s.describe()` returns a new `Series` containing descriptive statistics for the data in `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b0230-9368-4b76-a3bf-7e72e7641acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff[\"Hours\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ee43f-8d02-4788-a78e-2b7113c1386c",
   "metadata": {},
   "source": [
    "Defining a more meaningful index allows us to select specific values from a series just by referring to the desired key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0613bfe-c405-4aff-b50a-d9c8fa20c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff[\"Hours\"][\"Anna\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde2945-40d5-41d4-88bd-5b3ff10487fd",
   "metadata": {},
   "source": [
    "How can we compute the range of TA hours by calling the `min()` and `max()` functions? For this example dataset, the range should be 10 since Anna has 20 hours and Abiy has 10 hours for a difference of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927075e-9e07-4ce6-a431-48db54434838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5283b30-f536-4bae-a1e5-dc97f7180c3f",
   "metadata": {},
   "source": [
    "### Element-wise operations\n",
    "\n",
    "Let's consider a slightly more complex dataset that has more columns, like this made-up emissions dataset. The `pd.read_csv` function also includes an `index_col` parameter that you can use to set the index while reading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5992820-7a7a-4981-80b0-0b1711e1fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"\"\"\n",
    "City,Country,Emissions,Population\n",
    "New York,USA,200,1500\n",
    "Paris,France,48,42\n",
    "Beijing,China,300,2000\n",
    "Nice,France,40,60\n",
    "Seattle,USA,100,1000\n",
    "\"\"\"\n",
    "\n",
    "emissions = pd.read_csv(io.StringIO(csv), index_col=\"City\")\n",
    "emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83284b6-4f2f-4005-9c90-3a6ac2d746a7",
   "metadata": {},
   "source": [
    "`pandas` can help us answer questions like the emissions per capita: emissions divided by population for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a9721-e810-478f-862e-504e13b0f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions[\"Emissions\"] / emissions[\"Population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698e996-5b8f-42e1-aff5-ff43751d156b",
   "metadata": {},
   "source": [
    "Element-wise operations also work if one of the operands is a single value rather than a `Series`. For example, the following cell adds 4 to each city population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a9f00-cb81-42e6-be61-d6a3a26ed2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions[\"Population\"] + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da92261-03d2-48ec-bc45-ba67839ff7c0",
   "metadata": {},
   "source": [
    "## Row indexers\n",
    "\n",
    "All the above operations apply to every row in the original data frame. What if our questions involve returning just a few rows, like **filtering** the data to identify only the cities that have at least 200 emissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7469e9b-f880-4db6-aa23-450ea90d401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_emissions = emissions[\"Emissions\"] >= 200\n",
    "emissions[high_emissions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2bd5e-426e-49be-b346-d56db7c96344",
   "metadata": {},
   "source": [
    "This new syntax shows how we can filter a dataframe by indexing it with a boolean series. [PandasTutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20%22%22%22%0ACity,Country,Emissions,Population%0ANew%20York,USA,200,1500%0AParis,France,48,42%0ABeijing,China,300,2000%0ANice,France,40,60%0ASeattle,USA,100,1000%0A%22%22%22%0A%0Aemissions%20%3D%20pd.read_csv%28io.StringIO%28csv%29,%20index_col%3D%22City%22%29%0Aemissions%5Bemissions%5B%22Emissions%22%5D%20%3E%3D%20200%5D&d=2024-01-16&lang=py&v=v1) shows you how the above output is determined by selecting only the rows that are `True` in the following boolean series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83ceae-9ef9-4f1a-840d-d074920f110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cc201-cb38-4b2a-aefb-0d0b42c5dea3",
   "metadata": {},
   "source": [
    "Multiple conditions can be combined using the following element-wise operators.\n",
    "\n",
    "- `&` performs an element-wise `and` operation.\n",
    "- `|` performs an element-wise `or` operation.\n",
    "- `~` performs an element-wise `not` operation.\n",
    "\n",
    "Due to how Python evaluates order of operations, parentheses are required when combining masks in a single expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323df58-79fc-42fa-841b-2d29d2883925",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions[high_emissions | (emissions[\"Country\"] == \"USA\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a4f62-51a4-4cf4-a684-d187bb89b4e3",
   "metadata": {},
   "source": [
    "Write a one-line `pandas` expression that returns all the cities in France that have a population greater than 50 from the `emissions` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf5cae-0d37-4c3d-9caa-eeb3d5dcab9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd90a9e-4524-452e-ac29-95f527800610",
   "metadata": {},
   "source": [
    "## Selection by label\n",
    "\n",
    "To summarize what we've learned so far, `pandas` provides both column indexers and row indexers accessible through the square brackets notation.\n",
    "\n",
    "- `df[colname]` returns the corresponding `Series` from the `df`.\n",
    "- `df[boolean_series]` returns a new `DataFrame` containing just the rows specified `True` in the `boolean_series`.\n",
    "\n",
    "These two access methods are special cases of a more general `df.loc[rows, columns]` function that provides more functionality. For example, we can select just the city populations for cities with at least 200 emissions and visualize the procedure in [PandasTutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20%22%22%22%0ACity,Country,Emissions,Population%0ANew%20York,USA,200,1500%0AParis,France,48,42%0ABeijing,China,300,2000%0ANice,France,40,60%0ASeattle,USA,100,1000%0A%22%22%22%0A%0Aemissions%20%3D%20pd.read_csv%28io.StringIO%28csv%29,%20index_col%3D%22City%22%29%0Aemissions%5Bemissions%5B%22Emissions%22%5D%20%3E%3D%20200%5D&d=2024-01-17&lang=py&v=v1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04174898-3a64-41d6-97ae-1930a8047a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.loc[high_emissions, \"Population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf0b62-71a1-4f7b-825b-d393647da893",
   "metadata": {},
   "source": [
    "Whether a single value, a 1-dimensional `Series`, or a 2-dimensional `DataFrame` is returned depends on the selection.\n",
    "\n",
    "> Notice that label-based slicing includes the endpoint, unlike slicing a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e8cd0-8408-48d0-b4ed-24bbdd971251",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.loc[high_emissions, \"Country\":\"Population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bb7cc-4a42-40dd-9cc0-c338d9af4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.loc[:, [\"Country\", \"Emissions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723562f-a70a-43a8-a178-936d34e63f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.loc[\"Paris\", \"Country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef762b81-5497-4238-8719-b7ed6a176dc7",
   "metadata": {},
   "source": [
    "Returning to our prior `staff` hours example, we can get Anna's hours by using a single `df.loc[index, columns]` access rather than two separate accesses. This convenient syntax only works when we've specified a meaningful index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a5c33-5a79-4086-b19b-9f7748aeb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff.loc[\"Anna\", \"Hours\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2530e83-b604-46f8-80af-d92105fa16a6",
   "metadata": {},
   "source": [
    "## Practice: Largest earthquake place (Pandas)\n",
    "\n",
    "Previously, we learned about two ways to write Python code to read earthquakes as a list of dictionaries and return the name of the place with the largest-magnitude earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22aca2a-f78f-4c9d-9174-fd57dd1e609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_earthquake_place(path):\n",
    "    \"\"\"\n",
    "    Returns the name of the place with the largest-magnitude earthquake in the specified CSV file.\n",
    "\n",
    "    >>> largest_earthquake_place(\"earthquakes.csv\")\n",
    "    'Northern Mariana Islands'\n",
    "    \"\"\"\n",
    "    earthquakes = pd.read_csv(path).to_dict(\"records\")\n",
    "    max_name = None\n",
    "    max_magn = 0\n",
    "    for earthquake in earthquakes:\n",
    "        if earthquake[\"magnitude\"] > max_magn:\n",
    "            max_name = earthquake[\"name\"]\n",
    "            max_magn = earthquake[\"magnitude\"]\n",
    "    return max_name\n",
    "\n",
    "\n",
    "def largest_earthquake_place(path):\n",
    "    \"\"\"\n",
    "    Returns the name of the place with the largest-magnitude earthquake in the specified CSV file.\n",
    "\n",
    "    >>> largest_earthquake_place(\"earthquakes.csv\")\n",
    "    'Northern Mariana Islands'\n",
    "    \"\"\"\n",
    "    from operator import itemgetter\n",
    "    earthquakes = pd.read_csv(path).to_dict(\"records\")\n",
    "    return max(earthquakes, key=itemgetter(\"magnitude\"))[\"name\"]\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538436f-b40a-4005-bb4f-8cfa56904d57",
   "metadata": {},
   "source": [
    "How might we convert this program to solve the problem directly with a `DataFrame` instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bea3f-166c-46a0-be90-955e1b94b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_earthquake_place(path):\n",
    "    \"\"\"\n",
    "    Returns the name of the place with the largest-magnitude earthquake in the specified CSV file.\n",
    "\n",
    "    >>> largest_earthquake_place(\"earthquakes.csv\")\n",
    "    'Northern Mariana Islands'\n",
    "    \"\"\"\n",
    "    earthquakes = pd.read_csv(path, index_col=\"id\")\n",
    "    display(earthquakes) # Helpful for debugging: delete when done\n",
    "    ...\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "865aa20b-5f98-4439-a989-1d0551c55a6b",
   "metadata": {},
   "source": [
    "## Optional: Selection by position\n",
    "\n",
    "Everything we've learned so far is an example of label-based indexing. But it turns out there's another system of position-based indexing that is also available. Let's compare the 4 approaches.\n",
    "\n",
    "- `df[colname]` returns the corresponding `Series` from the `df`.\n",
    "  - `df[[col1, col2, ...]]` returns a new `DataFrame` containing the corresponding columns from the `df`.\n",
    "- `df[boolean_series]` returns a new `DataFrame` containing just the rows specified `True` in the `boolean_series`.\n",
    "- `df.loc[index, columns]` returns a single value, a `Series`, or a `DataFrame` for the **label-based selection** from the `df`.\n",
    "- `df.iloc[rows, columns]` returns a single value, a `Series`, or a `DataFrame` for the **position-based selection** from the `df`.\n",
    "\n",
    "Label-based indexing uses the bolded column and row indexers. Position-based indexing uses **purely integer-based indexing**. Slicing by position excludes the endpoint, just like slicing a Python list. We generally won't use position-based selections in this course, but you may run into code that uses them elsewhere.\n",
    "\n",
    "Position-based indexing is most useful when you have a position-based query that can't be easily specified using only label-based indexing. For example, we might know that we want to select just the rightmost two columns from a dataframe without knowing the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35520695-1c7b-4a39-b87a-3a417163f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.iloc[:, -2:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
