{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b037257-c5aa-4e16-90fb-04e9b2eb3d27",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "\n",
    "Last time, we learned about how to represent images in Python with `numpy`. In this lesson, we'll learn about convolutions, specifically on image data, and how to implement convolutions. By the end of this lesson, students will be able to:  \n",
    "\n",
    "- Define what image convolution is;\n",
    "- Recognize common kernels for image convolution and their functionalities;\n",
    "- Work with `numpy` arrays for representing images and kernels and applying convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2655d-bd06-4c86-bffd-2f49ceed0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97765644-9cf2-4ad5-8eee-3811e217f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d664487-858f-4bd9-86ed-01d822763dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_images(im1, im2):\n",
    "    \"\"\"\n",
    "    A helper function to display two images side by side.\n",
    "    \"\"\"\n",
    "    _, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    axs[0].imshow(im1, cmap=\"gray\")\n",
    "    axs[1].imshow(im2, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdb427-a7a0-4545-8935-2009c7562406",
   "metadata": {},
   "source": [
    "## Why Convolutions?\n",
    "\n",
    "Not only does it have an elegant mathematical definition and important theorems associated with it (you should watch 3Blue1Brown's [video](https://www.youtube.com/watch?v=KuXjwB4LzSA) on convolutions which will be way better than what I can explain), it is also an indispensable component of a lot of *important* neural network architectures, like the U-net,\n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" alt=\"u-net\" style=\"width:50%\"/>\n",
    "\n",
    "which underlies the stable diffusion model for text-to-image generation.\n",
    "\n",
    "<img src=\"https://ommer-lab.com/wp-content/uploads/2022/08/article-Figure3-1-1024x508.png\" alt=\"latent-diffusion\" style=\"width:50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d33575-059a-4249-aae7-9f2a3ac0e703",
   "metadata": {},
   "source": [
    "## Convolution as a Mathematical Operator\n",
    "\n",
    "Convolution defined mathematically is an operator that takes as input two functions ($f$ and $g$) and produces an third function ($f * g$) as output. Recall from last lesson that an image can be considered as a 2D function $F(x,y) = \\text{pixel value at x,y coordinate}$. (Think of this $F$ as a grayscale image with one channel; for colors images with multiple channels we can work with individual channels in the same way.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f7d9c-be07-45b0-8f62-7b8decabccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs = cv2.imread(\"dubs.jpg\", 0) # reads the image in as a grayscale image\n",
    "plt.imshow(dubs, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d65876-7d8f-4a19-a505-eafc44f5e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs.shape, dubs.ndim, dubs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbf075-5285-4b2e-a3f2-f5ab6480c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(100, 100)\n",
    "dubs[100, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab3d9c-f80f-4a93-bf48-9fedd4d96ca9",
   "metadata": {},
   "source": [
    "## Numpy Basics\n",
    "\n",
    "Before we begin the topic, let's first learn some basic methods for creating `numpy` arrays, which might be useful when we implement convolution later in this lesson. You've seen from last lesson that you can create `numpy` arrays from lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f035aac-5a09-40cd-9ced-bfa328ec1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb684022-0e1f-4c3b-aa8c-1ec1edc9591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(range(1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2b530-d9eb-49fe-a13c-2008cdb2e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1, 4) # Create an array with a range of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256684b7-1b51-4d50-9a0d-b2548de6ccca",
   "metadata": {},
   "source": [
    "There are also some specialized methods for creating filled arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176a0c6-fe82-4546-af55-c640d8fa02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of zeros\n",
    "zeros = np.zeros((2, 3))  # 2x3 array of zeros\n",
    "print(zeros)\n",
    "\n",
    "# Create an array of ones\n",
    "ones = np.ones((3, 2))  # 3x2 array of ones\n",
    "print(ones)\n",
    "\n",
    "# Create a 3D array of random numbers\n",
    "random_array = np.random.rand(2, 3, 4)  # 2x3x4 array of random numbers\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17244e-e28a-4255-81d1-eea9c9c0f139",
   "metadata": {},
   "source": [
    "## Image Convolutions\n",
    "\n",
    "Let's watch 3Blue1Brown's short video on image convolution as it's worth thousands of words in terms of explaining the concept.\n",
    "\n",
    "[![what is image convolution](https://img.youtube.com/vi/4xWpQe3G9qI/0.jpg)](https://www.youtube.com/watch?v=4xWpQe3G9qI)\n",
    "\n",
    "In the example shown in the video we are applying a 3x3 blur filter/kernel *matrix* to the image *matrix* that is basically averaging the pixels in a 3x3 patch.\n",
    "$$kernel = \\begin{bmatrix}\n",
    "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9}\\\\[0.3em]\n",
    "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9}\\\\[0.3em]\n",
    "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Here's how we can create this kernel in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e8935-5563-46df-bae5-5656bb37a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_kernel = 1 / 9 * np.ones((3, 3))\n",
    "blur_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ff71d-7fc4-48f2-bb83-55b67a7941fb",
   "metadata": {},
   "source": [
    "Why is it averaging? Because the sum of the entries in the kernel is 1. The entries are like weights applied to a set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85fb82-dcfc-48e3-9619-2ca7b72f4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(blur_kernel), blur_kernel.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd50845-0f97-4aa6-9983-ad41d4766103",
   "metadata": {},
   "source": [
    "The kernel needs to be flipped both left to right and upside down but in many implementations it stays unflipped and the implemented operation becomes effectively cross-correlation instead of convolution. There's usually no need to distinguish the two for image convolutions and we can just go with the option that's easier to reason about.\n",
    "\n",
    "<img src=\"flip_fg.png\" style=\"width:50%\"/>\n",
    "\n",
    "We can do this because the kernels that are used are often invariant under flipping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bcfdc-a011-4bc9-a1f4-000e3329232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fliplr(np.flipud(blur_kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326ede9-2539-4e31-883f-1853bcc69266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not true for symmetric matrices\n",
    "onetwothree = np.array([[1,2,3],[2,2,3],[3,3,3]])\n",
    "print(onetwothree)\n",
    "print(onetwothree.T)\n",
    "onetwothree_flipped = np.fliplr(np.flipud(onetwothree))\n",
    "print(onetwothree_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736d671-15f1-40c7-b2e1-f09cf57f3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not to mention any matrix\n",
    "random_arr = np.random.rand(3,3)\n",
    "print(random_arr)\n",
    "random_arr_flipped = np.fliplr(np.flipud(random_arr))\n",
    "print(random_arr_flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abb0d0-4db4-4afe-93be-28657ae0dcbc",
   "metadata": {},
   "source": [
    "### Practice: code the convolution for images\n",
    "\n",
    "A convolution can be thought of as a special way of looping over the pixels in an image. Instead of looping over an image one pixel at a time, a convolution loops over an image one subimage (sliced portion of the image) at a time. We call a convolution a **sliding window algorithm** because the algorithm starts at the top row, generates the first subimage for the top leftmost corner, then slides over 1 pixel to the right, and repeats the process.\n",
    "\n",
    "The sum of the element-wise product between the subimage matrix generated at pixel $(x,y)$ and the kernel matrix becomes the new value at the convolution image's pixel $(x,y)$. It can be written as: $$(f * g) [x, y] = \\sum_{i\\in[n],j\\in[m]} f[x-i, y-j] g[i, j]$$\n",
    "where $f$ is a single-channel image and $g$ is an $n\\text{ by }m$ kernel matrix.\n",
    "\n",
    "When looping over an image, we need to consider what should happen at the boundary. There are multiple ways to handle boundary values, and below are the three modes (2D version) used in `numpy.convolve`, a [function](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html) for doing 1D convolutions.\n",
    "\n",
    "<img src=\"conv_modes.png\" style=\"width:50%\"/>\n",
    "\n",
    "And for \"full\" and \"same\", there's also subtlety in how to fill the imaginary values outside of the image boundary. Depending on your inputs and applications/goals, this could also be different. For now, we'll just consider the \"valid\" mode and not worry about how to handle boundary values.\n",
    "\n",
    "Discuss with your neighbors for 30 seconds before we start: what are the sizes of the convolution results for the three modes? Write them in terms of image_width (iW), image_height (iH), kernel_width (kW), kernel_height (kH).\n",
    "\n",
    "<details><summary>answer</summary>\n",
    "<ul>\n",
    "<li> full: image_width + kernel_width - 1, image_height + kernel_height - 1</li>\n",
    "<li> same: image_width,                    image_height</li>\n",
    "<li>valid: image_width - kernel_width + 1, image_height - kernel_height + 1</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13893aa-42fe-4ac0-a085-c457aff6e465",
   "metadata": {},
   "source": [
    "Let's now practice coding 2D convolution in Python under the \"valid\" mode.\n",
    "\n",
    "**Task 1**: first, think of how to iterate over an image to obtain the subimages the same size as the kernel.  \n",
    "\n",
    "PollEverywhere question: which of the following options do you think generate the correct subimages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1e74f-0b27-4415-99e1-7ef0e6f2dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subimages(im, kernel):\n",
    "    \"\"\"\n",
    "    Takes as input an image (single-channel) and a kernel/filter, both being numpy arrays.\n",
    "    Iterate over im to obtain the subimages the same size as the kernel and\n",
    "    return the subimages as a dictionary keyed by pixel coordinates.\n",
    "    \"\"\"\n",
    "    assert im.ndim == 2, kernel.ndim == 2\n",
    "    image_w, image_h = im.shape\n",
    "    kernel_w, kernel_h = kernel.shape\n",
    "    conv_im_w = image_w - kernel_w + 1\n",
    "    conv_im_h = image_h - kernel_h + 1\n",
    "\n",
    "    subimages = {}\n",
    "    for x in range(conv_im_w):\n",
    "        for y in range(conv_im_h):\n",
    "            ## option 1\n",
    "            subimage = im[x - 1:x + kernel_w - 1, y - 1:y + kernel_h - 1]\n",
    "            ## option 2\n",
    "            # subimage = im[x    :x + kernel_w,     y:  y + kernel_h]\n",
    "            ## option 3\n",
    "            # subimage = im[x    :x + kernel_w + 1, y:  y + kernel_h + 1]\n",
    "            ## option == 4:\n",
    "            # subimage = im[x + 1:x + kernel_w + 1, y + 1:y + kernel_h + 1]\n",
    "            ## option == 5:\n",
    "            # subimage = im[y    :y + kernel_h,     x:  x + kernel_w]\n",
    "            subimages[x, y] = subimage\n",
    "    return subimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658dbbfe-dc90-48e5-8bb3-b29922015d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up our test case\n",
    "small_dubs = np.copy(dubs[50:100, 300:350])\n",
    "compare_two_images(small_dubs, small_dubs[30:33,20:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba86559-5fb4-46c3-910b-b570b149b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the method\n",
    "small_dubs_subimages = get_subimages(small_dubs, blur_kernel)\n",
    "compare_two_images(small_dubs_subimages[(30, 20)], small_dubs[30:33,20:23]) # visual comparison is usually the most helpful\n",
    "\n",
    "assert small_dubs_subimages[(30, 20)].shape == blur_kernel.shape, \"subimage does not have same size as the kernel\"\n",
    "assert np.allclose(small_dubs_subimages[(30, 20)], small_dubs[30:33,20:23]), \"subimage does not match the expected subimage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3e31e-17fc-4ac8-a4cd-4e0198d17a43",
   "metadata": {},
   "source": [
    "**Task 2**: compute the value at $x,y$ and assign to the array representing the convolution result.\n",
    "\n",
    "PollEverywhere question: this value is a sum of an elementwise product; fill in the code for the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d5d3f-f754-49f2-9f7e-13ae2ea30efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_conv(im, kernel):\n",
    "    \"\"\"\n",
    "    Takes as input an image (single-channel) and a kernel/filter, both being numpy arrays.\n",
    "    Returns the convolution of the kernel over the image under the \"valid\" mode\n",
    "    where the image size shrinks by the size of the kernel.\n",
    "    \"\"\"\n",
    "    assert im.ndim == 2, kernel.ndim == 2\n",
    "    image_w, image_h = im.shape\n",
    "    kernel_w, kernel_h = kernel.shape\n",
    "    conv_im_w = image_w - kernel_w + 1\n",
    "    conv_im_h = image_h - kernel_h + 1\n",
    "    conv_image = np.zeros((conv_im_w, conv_im_h))\n",
    "\n",
    "    for x in range(conv_im_w):\n",
    "        for y in range(conv_im_h):\n",
    "            ...\n",
    "\n",
    "    return conv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e40a2-1907-4e87-a6ea-34892607b22b",
   "metadata": {},
   "source": [
    "Let's see what the blur kernel does to the dubs image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487c159-fad8-4b86-8476-f9136d2d4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs_blurred = im_conv(dubs, blur_kernel)\n",
    "compare_two_images(dubs, dubs_blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94643923-a935-4032-95fe-5593eeae18f7",
   "metadata": {},
   "source": [
    "What if we make the kernel size larger? Discuss with your neighbors what might be the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933b062-5247-4689-ac9c-ed0444231f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_kernel_5x5 = np.ones((5,5))\n",
    "blur_kernel_5x5 /= blur_kernel_5x5.size\n",
    "blur_kernel_5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692429fd-f4c3-45f5-9e64-043f7bc5e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs_blurred_5x5 = im_conv(dubs, blur_kernel_5x5)\n",
    "compare_two_images(dubs, dubs_blurred_5x5)\n",
    "compare_two_images(dubs_blurred, dubs_blurred_5x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b5312-1d0d-4af3-aa8f-6f625f19ea12",
   "metadata": {},
   "source": [
    "### More filters/kernels\n",
    "\n",
    "So far we've seen averaging filters/box blur filters. Next let's try to deduce what a kernel might do to an image.\n",
    "\n",
    "#### Kernel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a23830-337c-4e53-9dbd-f8c5d4564e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.zeros((3,3))\n",
    "kernel[1,1] = 1\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bc026-0778-4f1f-bb3a-21246281cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_im = im_conv(dubs, kernel)\n",
    "compare_two_images(dubs, conv_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c0399-5953-4f53-a763-8a7872bd8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dubs.shape, conv_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80bb40-b823-4451-8bc7-673100a44e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(dubs[1:-1, 1:-1], conv_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68850ab-4b41-4a17-b603-bfaf3dc7e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_kernel = np.zeros((3,3))\n",
    "identity_kernel[1,1] = 1\n",
    "identity_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41b21b-d538-468e-8c3b-dd0017ff867f",
   "metadata": {},
   "source": [
    "#### Kernel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fdb5d-48f0-4a4d-a678-15b833c3bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 2 * identity_kernel - blur_kernel\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9504ffe-a2a9-489b-858a-2f2de1e7debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_im = im_conv(dubs, kernel)\n",
    "compare_two_images(dubs, conv_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d18c5-1c70-4662-ac2a-90b78e8e1d09",
   "metadata": {},
   "source": [
    "You might think that it looks darker, but looking closer it also seems that the hair strands stand out more. Let's take a look at the result of applying convolution to the identity_kernel with the blur_kernel subtracted from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6c4fb-90f1-4813-8b4c-f7c19d27ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_image_id_sub_blur = im_conv(dubs, identity_kernel - blur_kernel)\n",
    "plt.imshow(conv_image_id_sub_blur, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bdaa43-1085-460c-bfdf-615902db8e2d",
   "metadata": {},
   "source": [
    "It's kind of hard to see so let's do some thresholding to turn all the gray pixels black and the others white to make the pattern easier to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e74bfe-8749-4dbc-8d3a-a43c90322024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.threshold(conv_image_id_sub_blur, 15, 200, cv2.THRESH_BINARY)[1], cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef65d8-8da7-4476-8f48-66fdab1c3047",
   "metadata": {},
   "source": [
    "Intuitively, this is subtracting the blurred image from the original image, leaving with us the places where the pixels change colors. You could say that these regions are the important silhouettes that let us recognize the pattern in the image. Now if we apply the sum of the identity_kernel and this difference (identity_kernel - blur_kernel) as a kernel to the image, it's like adding these regions back to the original image, which further stresses them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b04511-7a3b-4a30-8d1d-4fea3b5106f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpening_kernel = 2 * identity_kernel - blur_kernel\n",
    "sharpening_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbf5ae-fa99-4444-bf34-3f2af1bcdaa1",
   "metadata": {},
   "source": [
    "### Kernel 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab647f-dc42-47ce-9b8f-b87399b97201",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_blur_kernel = np.array([[1,4,6,4,1]]) * np.array([[1,4,6,4,1]]).T\n",
    "print(gaussian_blur_kernel)\n",
    "gaussian_blur_kernel = gaussian_blur_kernel / 256\n",
    "gaussian_blur_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375061a-edc4-4781-a1bb-b1e854745870",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_im = im_conv(dubs, gaussian_blur_kernel)\n",
    "compare_two_images(dubs, conv_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0432e-11e2-4d67-bee3-7c897fc46b2a",
   "metadata": {},
   "source": [
    "### OpenCV and some examples\n",
    "\n",
    "OpenCV is a python library that provides many useful image processing methods, including convolution filters. Note that there's some difference between the implementations that opencv uses and we have introduced in class but the overall result should be qualitatively similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbbb83-de0d-434e-b6f4-4d3f574a501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sharpening kernel\n",
    "sharpened_image = cv2.filter2D(dubs, -1, sharpening_kernel)\n",
    "plt.imshow(sharpened_image, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b5eff-16bc-4d3c-b7a4-68009c77b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the (approximate) Gaussian blur\n",
    "blurred_filtered_image = cv2.filter2D(dubs, -1, gaussian_blur_kernel)\n",
    "# alternatively, use opencv's Gaussian blur\n",
    "# blurred_filtered_image = cv2.GaussianBlur(dubs, (5, 5), 0)\n",
    "plt.imshow(blurred_filtered_image, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43eb949-262b-4669-b6bb-2f393522ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an edge detection filter kernel\n",
    "edge_kernel = np.array([[-1, -1, -1],\n",
    "                        [-1, 8, -1],\n",
    "                        [-1, -1, -1]])\n",
    "edge_filtered_image = cv2.filter2D(dubs, -1, edge_kernel)\n",
    "plt.imshow(edge_filtered_image, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a43aa-4b63-4c08-b445-6b9a7911145a",
   "metadata": {},
   "source": [
    "Here's an example of how to do edge detection of an image in opencv. You can read the [documentation](https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga2a671611e104c093843d7b7fc46d24af)/[tutorial](https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html) for what the parameters actually do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b88ed-406a-4794-9c5e-8f574614d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection\n",
    "edges_orig = cv2.Canny(dubs, 100, 200)\n",
    "edges_blurred = cv2.Canny(blurred_filtered_image, 100, 200)\n",
    "compare_two_images(edges_orig, edges_blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a75898-e305-41dd-aaa7-4e1fcb26c118",
   "metadata": {},
   "source": [
    "There are many more useful methods for doing image processing and computer vision tasks, not just convolutions, in opencv. For example, when preparing image data for ML model training, it's often necessary to transform the images to be a certain dimension, split off the channels, or compute simple features off of the images and put them into a different vector. For anyone working with image data for their projects, it is a great tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
