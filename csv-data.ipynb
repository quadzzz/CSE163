{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a53ab8e-0a96-4209-b13e-449440b75b97",
   "metadata": {},
   "source": [
    "# CSV Data\n",
    "\n",
    "In this lesson, we'll learn more advanced dictionary features and the CSV data file format. By the end of this lesson, students will be able to:\n",
    "\n",
    "- Loop over the `keys`, `values`, and `items` of a dictionary.\n",
    "- Identify the list of dictionaries corresponding to some CSV data.\n",
    "- Loop over a list of dictionaries (CSV rows) and access dictionary values (CSV columns).\n",
    "\n",
    "## Dictionary functions\n",
    "\n",
    "Dictionaries, like lists, are also mutable data structures so they have functions to help store and retrieve elements.\n",
    "\n",
    "- `d.pop(key)` removes `key` from `d`.\n",
    "- `d.keys()` returns a collection of all the keys in `d`.\n",
    "- `d.values()` returns a collection of all the values in `d`.\n",
    "- `d.items()` returns a collection of all `(key, value)` tuples in `d`.\n",
    "\n",
    "There are different ways to loop over a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca794c6-2d26-4cce-8096-50070ecb0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "for key in dictionary:\n",
    "    print(key, dictionary[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806f16e-f0c1-45a8-9e91-38114b94af42",
   "metadata": {},
   "source": [
    "## None in Python\n",
    "\n",
    "In an earlier lesson, we wrote a function to count the occurrences of each token in a file as a `dict` where the keys are words and the values are counts.\n",
    "\n",
    "```\n",
    "{\"green\": 2, \"eggs\": 6, \"and\": 3, \"yam\": 2}\n",
    "```\n",
    "\n",
    "Suppose we want to debug the following function `most_frequent` that takes this dictionary as *input* and returns the word with the highest count. If the input were a list, we could index the zero-th element from the list and loop over the remaining values by slicing the list. But it's harder to do this with a dictionary.\n",
    "\n",
    "Python has a special `None` keyword, like `null` in Java, that represents a placeholder value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084590d8-f37f-4852-bc76-f8ebbb0a7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(counts):\n",
    "    \"\"\"\n",
    "    Returns the token in the given dictionary with the highest count, or None if empty.\n",
    "\n",
    "    >>> most_frequent({\"green\": 2, \"eggs\": 6, \"and\": 3, \"yam\": 2})\n",
    "    'eggs'\n",
    "    >>> most_frequent({}) # None is not displayed as output\n",
    "\n",
    "    \"\"\"\n",
    "    max_word = None\n",
    "    for word in counts:\n",
    "        if counts[word] > counts[max_word]:\n",
    "            max_word = word\n",
    "    return max_word\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c4201-d35f-4517-abe6-a4deb955ec79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Loop unpacking\n",
    "\n",
    "When we need keys and values, we can loop over and unpack each key-value pair by looping over the `dictionary.items()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791f854-9d73-4a11-aad4-cf2b8a07b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "for key, value in dictionary.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf82976-1a50-4125-9920-fff642782996",
   "metadata": {},
   "source": [
    "Loop unpacking is not only useful for dictionaries, but also for looping over other sequences such as `enumerate` and `zip`. `enumerate` is a built-in function that takes a sequence and returns another sequence of pairs representing the element index and the element value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735741f6-b5df-4548-8b23-26ca0bd67cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"poem.txt\") as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        print(i, line[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e4520-de85-40af-9dcf-da497e0fa675",
   "metadata": {},
   "source": [
    "`zip` is another built-in function that takes one or more sequences and returns a *sequence of tuples* consisting of the first element from each given sequence, the second element from each given sequence, etc. If the sequences are not all the same length, `zip` stops after yielding all elements from the shortest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614855c-ed37-428a-a00a-e1212f17e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_nums = [  1,    2,     3,    4,   5]\n",
    "alpha_nums  = [\"a\",  \"b\",   \"c\",  \"d\", \"e\"]\n",
    "roman_nums  = [\"i\", \"ii\", \"iii\", \"iv\", \"v\"]\n",
    "\n",
    "for arabic, alpha, roman in zip(arabic_nums, alpha_nums, roman_nums):\n",
    "    print(arabic, alpha, roman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994834c-2bf7-4ab4-ba85-8d32d1cc89be",
   "metadata": {},
   "source": [
    "## Comma-separated values\n",
    "\n",
    "In data science, we often work with tabular data such as the following table representing the names and hours of some of the TAs.\n",
    "\n",
    "Name | Hours\n",
    "-----|-----:\n",
    "Anna | 20\n",
    "Iris | 15\n",
    "Abiy | 10\n",
    "Gege | 12\n",
    "\n",
    "A **table** has two main components to it:\n",
    "\n",
    "- **Rows** corresponding to each entry, such as each individual TA.\n",
    "- **Columns** corresponding to (required or optional) fields for each entry, such as TA name and TA hours.\n",
    "\n",
    "A **comma-separated values** (CSV) file is a particular way of representing a table using only plain text. Here is the corresponding CSV file for the above table. Each row is separated with a newline. Each column is separated with a single comma `,`.\n",
    "\n",
    "```\n",
    "Name,Hours\n",
    "Anna,20\n",
    "Iris,15\n",
    "Abiy,10\n",
    "Gege,12\n",
    "```\n",
    "\n",
    "We'll learn a couple ways of processing CSV data in this course, first of which is representing the data as a **list of dictionaries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d463e-9ecd-46c1-aacc-1bdffae1c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff = [\n",
    "    {\"Name\": \"Anna\", \"Hours\": 20},\n",
    "    {\"Name\": \"Iris\", \"Hours\": 15},\n",
    "    {\"Name\": \"Abiy\", \"Hours\": 10},\n",
    "    {\"Name\": \"Gege\", \"Hours\": 12},\n",
    "]\n",
    "staff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2eeac-0253-4bc3-b5b9-ec708d56a425",
   "metadata": {},
   "source": [
    "To see the total number of TA hours available, we can loop over the list of dictionaries and sum the \"Hours\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc7fda-d50c-4a74-8771-6ae1154bc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hours = 0\n",
    "for ta in staff:\n",
    "    total_hours += ta[\"Hours\"]\n",
    "total_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e76d800-bf01-4a9a-8578-1f187486fbd3",
   "metadata": {},
   "source": [
    "What are some different ways to get the value of Iris's hours?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0a542-abb4-4583-8abe-af435c250162",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Practice: Largest earthquake place\n",
    "\n",
    "Suppose we have a dataset of earthquakes around the world stored in the CSV file `earthquakes.csv`.\n",
    "\n",
    "id | year | month | day | latitude | longitude | name | magnitude\n",
    "---|:----:|:-----:|:---:|---------:|----------:|------|---------:\n",
    "nc72666881 | 2016 | 7 | 27 | 37.672 | -121.619 | California | 1.43\n",
    "us20006i0y | 2016 | 7 | 27 | 21.515 | 94.572 | Burma | 4.9\n",
    "nc72666891 | 2016 | 7 | 27 | 37.577 | -118.859 | California | 0.06\n",
    "nc72666896 | 2016 | 7 | 27 | 37.596 | -118.995 | California | 0.4\n",
    "nn00553447 | 2016 | 7 | 27 | 39.378 | -119.845 | Nevada | 0.3\n",
    "\n",
    "Write a function `largest_earthquake_place` that takes the earthquake `data` represented as a list of dictionaries and returns the name of the location that experienced the largest earthquake. If there are no rows in the dataset (no data at all), return `None`.\n",
    "\n",
    "For example, considering only the data shown above, the result would be `\"Burma\"` because it had the earthquake with the largest magnitude (4.9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4b7e1-f224-4bd6-9cc6-f1c61bbb23ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def largest_earthquake_place(path):\n",
    "    \"\"\"\n",
    "    Returns the name of the place with the largest-magnitude earthquake in the specified CSV file.\n",
    "\n",
    "    >>> largest_earthquake_place(\"earthquakes.csv\")\n",
    "    'Northern Mariana Islands'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    earthquakes = pd.read_csv(path).to_dict(\"records\")\n",
    "    ...\n",
    "\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
